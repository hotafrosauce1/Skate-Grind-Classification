{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import numpy as np\n",
    "import PIL\n",
    "from matplotlib import image\n",
    "from os import listdir\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all of the images, resizing them,\n",
    "# and storing them in a dictionary according to\n",
    "# their respective classifications\n",
    "\n",
    "loaded_images = {}\n",
    "\n",
    "trick_classes = [\n",
    "    '50-50 Grinds',\n",
    "    'Crooks and Overcrooks',\n",
    "]\n",
    "\n",
    "for trick in trick_classes:\n",
    "    img_num = 1\n",
    "    image_directory = 'Skate Images/{}'.format(trick)\n",
    "    \n",
    "    for filename in listdir(image_directory):\n",
    "        if '.DS_Store' in filename:\n",
    "            continue\n",
    "        if trick not in loaded_images.keys():\n",
    "            loaded_images[trick] = []\n",
    "        else:\n",
    "            img_loc = 'Skate Images/{}/{}'.format(trick, filename)\n",
    "            img_resized_loc = '{}/original-resized-{}.jpg'.format(image_directory, img_num)\n",
    "            \n",
    "            img = PIL.Image.open(img_loc)\n",
    "            img_resized = img.resize((300,300))\n",
    "            \n",
    "            img_resized.save(img_resized_loc)            \n",
    "\n",
    "            img_resized_data = image.imread(img_resized_loc)\n",
    "\n",
    "            if img_resized_data.shape == (300,300):\n",
    "                continue\n",
    "            \n",
    "            loaded_images[trick].append(img_resized_data)\n",
    "            img_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the training images are resized to 256 x 256 pixels\n",
    "for trick in loaded_images.keys():\n",
    "    print(loaded_images[trick][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of training images\n",
    "print(sum([len(trick_list) for trick_list in loaded_images.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images per trick category\n",
    "print(\"Number of images for each trick category: \\n\")\n",
    "for trick in loaded_images.keys():\n",
    "    num_images = len(loaded_images[trick])\n",
    "    print('---> {} ({} images)'.format(trick, num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(loaded_images['Crooks and Overcrooks'][53])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing ConvNet model\n",
    "model = Sequential()\n",
    "weight_initializer = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "regularizer = keras.regularizers.l2(l=0.1)\n",
    "dense_regularizer = keras.regularizers.l2(l=0.1)\n",
    "\n",
    "model.add(Conv2D(filters = 32, \n",
    "                 kernel_regularizer=regularizer,\n",
    "                 kernel_initializer=weight_initializer,\n",
    "                 kernel_size = (3,3),\n",
    "                 input_shape = (300,300,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 32,\n",
    "                 kernel_regularizer=regularizer,\n",
    "                 kernel_initializer=weight_initializer,\n",
    "                 kernel_size = (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 64,\n",
    "                 kernel_regularizer=regularizer,\n",
    "                 kernel_initializer=weight_initializer,\n",
    "                 kernel_size = (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 64,\n",
    "                 kernel_regularizer=regularizer,\n",
    "                 kernel_initializer=weight_initializer,\n",
    "                 kernel_size = (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, kernel_initializer=weight_initializer,kernel_regularizer=dense_regularizer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(128, kernel_initializer=weight_initializer,kernel_regularizer=dense_regularizer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#Compiling model\n",
    "sgd = optimizers.sgd(lr = 0.001)\n",
    "adam = optimizers.adam(0.0001)\n",
    "model.compile(optimizer = adam,\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = []\n",
    "output = []\n",
    "\n",
    "trick_map = {\n",
    "    '5-0 Grinds' : '5-0 Grind',\n",
    "    '50-50 Grinds' :  '50-50 Grind',\n",
    "    'Crooks and Overcrooks' : 'Crooked Grind or Overcrook Grind',\n",
    "    'Feeble Grinds' : 'Feeble Grind',\n",
    "    'Lipslides and Boardslides' : 'Lipslide or Boardslide',\n",
    "    'Nose Grinds' : 'Nose Grind',\n",
    "    'Noseslides and Tailslides' : 'Noseslide or Tailslide',\n",
    "    'Smith Grinds' : 'Smith Grind'\n",
    "}\n",
    "\n",
    "for trick in trick_classes:\n",
    "    trick_images = loaded_images[trick]\n",
    "    num_images = len(trick_images)\n",
    "    image_labels = [trick_map[trick] for _ in range(num_images)]\n",
    "    for image, label in zip(trick_images, image_labels):\n",
    "        input_images.append(image)\n",
    "        output.append(label)\n",
    "        \n",
    "output = np.array(output)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "vec = label_encoder.fit_transform(output)\n",
    "one_hot_labels = keras.utils.to_categorical(vec, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = np.array(input_images)\n",
    "# input_images = np.array(list(map(lambda x: x / 255, input_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(input_images[68])\n",
    "one_hot_labels[68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "datagen = ImageDataGenerator(height_shift_range = 0.15,\n",
    "                             horizontal_flip=True,\n",
    "                             width_shift_range = 0.15,\n",
    "                             rotation_range = 15,\n",
    "                             rescale= 1.0/255,\n",
    "                             zoom_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "# configure batch size and retrieve one batch of images\n",
    "os.makedirs('images')\n",
    "\n",
    "# fit parameters from data\n",
    "datagen.fit(input_images)\n",
    "\n",
    "i = 1\n",
    "aug_images = []\n",
    "aug_labels = []\n",
    "for X_batch, y_batch in datagen.flow(input_images, one_hot_labels, batch_size=100, save_to_dir='images', save_prefix='aug', save_format='jpg'):\n",
    "    if i == 50:\n",
    "        break\n",
    "    for X_aug_example, y_aug_example in zip(X_batch, y_batch):\n",
    "        aug_images.append(X_aug_example)\n",
    "        aug_labels.append(y_aug_example)\n",
    "    i += 1\n",
    "\n",
    "aug_images = np.array(aug_images)\n",
    "aug_labels = np.array(aug_labels)\n",
    "\n",
    "input_images = np.vstack((input_images, aug_images))\n",
    "one_hot_labels = np.vstack((one_hot_labels, aug_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(input_images, \n",
    "                                                     one_hot_labels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We now have {} images in total.'.format(len(X_train) + len(X_test)))\n",
    "print('There are {} training images and {} testing images.'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[570])\n",
    "print(y_train[570])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          validation_data = (X_test, y_test),\n",
    "          batch_size = 10,\n",
    "          epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
